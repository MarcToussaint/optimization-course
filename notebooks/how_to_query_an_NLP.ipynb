{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a benchmark problem\n",
    "This tutorial shows how to use and query a benchmark problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../build')\n",
    "import numpy as np\n",
    "import libry as ry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There a 6 benchmarks in total:** 3 scenarios, each with sequence or path variant. The sequence variants have dense Jacobians and optimize over a discrete sequence of few (maybe one) configurations; the path variants optimize over a whole continuous path and have sparse Jacobians.\n",
    "\n",
    "*All problems neglect collisions.* Esp. the last one has lots of collisions. But there are other difficulties in the last one.\n",
    "\n",
    "The following loads a benchmark problem, from which we get the ry.MathematicalProgram interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = ry.OptBench_Skeleton_Pick(ry.arg.path)  #1. scenario: simple pick, just one configuration or path\n",
    "#benchmark = ry.OptBench_Skeleton_Handover(ry.arg.path) #2. scenario: pick-handover-touch, 3 configurations or path\n",
    "#benchmark = ry.OptBench_Skeleton_StackAndBalance(ry.arg.sequence) #3. scenario: pick boxes and stack\n",
    "nlp = benchmark.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want, get a full API:\n",
    "#help(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method to use is `getInitializationSample`, which returns an initial x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nlp.getInitializationSample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important method is `evaluate(x)`, which returns a tuple `(phi,J)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(phi,J) = nlp.evaluate(x)\n",
    "print('phi=', phi, '\\nJ=', J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dimensionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dim(x)=', nlp.getDimension())\n",
    "print('dim(x)=', x.shape)\n",
    "print('dim(phi)=', phi.shape)\n",
    "print('dim(J)=', J.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features `phi` define all cost terms and inequality/equality constraint values. The feature types tell you, which feature entries refer to costs/constraints. For each feature, an integer is returned -- but actually it is an enum. So you can test equality with ry.OT.f, ry.OT.sos, ry.OT.ineq, or ry.OT.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = nlp.getFeatureTypes()\n",
    "print(types)\n",
    "print(types[0] == ry.OT.f)\n",
    "print(types[0] == ry.OT.sos)\n",
    "print(types[0] == ry.OT.ineq)\n",
    "print(types[0] == ry.OT.eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the benchmarks, most features are features are sum-of-square features (e.g. from control costs). Some are equality constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the benchmark problems implement a report method, which should help you to get more insight in what $x$ means and what is computed. For high verbosity it also displays something - in our case the robot in pose $x$.\n",
    "\n",
    "**Hit ENTER in the displayed window** to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the report method generally returns some info string - internal information given by the benchmark implementation\n",
    "print(nlp.report(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo for testing\n",
    "Calling the rai optimizer as below is just for testing - you're supposed to instead implement your own solvers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a solver with that problem\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(nlp)\n",
    "solver.setSolver(ry.NLP_SolverID.augmentedLag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve it\n",
    "solver.solve(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trace of queries\n",
    "solver.getTrace_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the trace of objectives for each query: the first is total cost, 2nd is ineq, 3rd is eq\n",
    "solver.getTrace_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.report(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = 0\n",
    "benchmark = 0\n",
    "solver = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
